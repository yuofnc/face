{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input, Dense, Dropout,Reshape, Flatten\n",
    "from keras.layers.pooling import MaxPooling2D,AveragePooling2D\n",
    "from keras.layers import Conv2D, BatchNormalization,UpSampling2D,Merge\n",
    "from keras.layers import Add,GlobalAveragePooling2D, Lambda, Conv2D,  Dropout, Dense, Flatten, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import concatenate\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "FILE_PATH = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\face_CNN_model_final.h5'\n",
    "trainpath = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\new_data_50000\\\\50000train\\\\'\n",
    "testpath = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\new_data_50000\\\\50000test\\\\'\n",
    "\n",
    "trainpath2 = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\convdata\\\\50000train\\\\'\n",
    "testpath2 = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\convdata\\\\50000test\\\\'\n",
    "\n",
    "FILE_PATH = 'h:\\\\facedata\\\\face_CNN_model_final.h5'\n",
    "trainpath = 'h:\\\\facedata\\\\new_data_50000\\\\50000train\\\\'\n",
    "testpath = 'h:\\\\facedata\\\\new_data_50000\\\\50000test\\\\'\n",
    "\n",
    "trainpath2 = 'h:\\\\facedata\\\\convdata\\\\50000train\\\\'\n",
    "testpath2 = 'h:\\\\facedata\\\\convdata\\\\50000test\\\\'\n",
    "\n",
    "K.set_floatx('float32')\n",
    "\n",
    "imgsize = 178\n",
    "train_samples = 40000\n",
    "test_samples = 200\n",
    "batch_size = 12\n",
    "\n",
    "chanDim = -1\n",
    "\n",
    "model_input6 = Input(shape=(178,178,3))\n",
    "input_shape = (178, 178, 3)\n",
    "\n",
    "\n",
    "model_inputconv = Input(shape=(80,80,3))\n",
    "input_shapeconv = (80, 80, 3)\n",
    "\n",
    "\n",
    "model_inputconv2 = Input(shape=(40,40,3))\n",
    "\n",
    "traindata =[]\n",
    "traindata2 =[]\n",
    "traindataok=[]\n",
    "traincount = 0\n",
    "testdata = []\n",
    "testdata2 = []\n",
    "testdataok=[]\n",
    "testcount = 0\n",
    "\n",
    "\n",
    "def sliceuse(x,index):\n",
    "    return x[:,:,:,index]\n",
    "\n",
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "def splitdata(x,inum,index):\n",
    "    da = K.int_shape(x)[1]\n",
    "    #print('data num:',da)\n",
    "    splitd = (int)(da/inum*2)\n",
    "    #test = x[:,0:splitd,0:splitd,:]\n",
    "    #print('test',test)\n",
    "    \n",
    "    if index ==0:\n",
    "        return x[:,0:splitd,0:splitd,:]\n",
    "    if index ==1:\n",
    "        return x[:,0:splitd,splitd:,:]\n",
    "    if index ==2:\n",
    "        return x[:,splitd:,0:splitd,:]\n",
    "    return x[:,splitd:,splitd:,:]\n",
    "    \n",
    "    #resu = []\n",
    "    #return  np.array(x[:,0:splitd,0:splitd,:]),  np.array(x[:,0:splitd,splitd:,:]), np.array(x[:,splitd:,0:splitd,:]), np.array(x[:,splitd:,splitd:,:])\n",
    "#K.int_shape(x)[0]\n",
    "\n",
    "def point(img,x,y):\n",
    "    cv2.circle(img,(x,y),1,(0,0,255),10)\n",
    "\n",
    "def msesum(y_true, y_pred):\n",
    "    return K.sum(K.abs(y_pred - y_true), axis=-1)*100\n",
    "\n",
    "def printResu27(modelpr,testcheck,testok):\n",
    "    img = testcheck[0:60]\n",
    "    imgok =testok[0:60]\n",
    "    predict = modelpr.predict(img)\n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    p5 = img[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [80,80,3]\n",
    "    p2.shape = [80,80,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [80,80,3]\n",
    "    p6.shape = [80,80,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [80,80,3]\n",
    "    p8.shape = [80,80,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(1, 3, 2)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def printResu28(modelpr,testcheck,testok):\n",
    "    img = testcheck[0:60]\n",
    "    imgok =testok[0:60]\n",
    "    predict = modelpr.predict(img)\n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    p5 = img[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [80,80,3]\n",
    "    p2.shape = [40,40,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [80,80,3]\n",
    "    p6.shape = [40,40,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [80,80,3]\n",
    "    p8.shape = [40,40,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(1, 3, 2)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def printResu2(modelpr):\n",
    "    printResu27(modelpr,testdataok,testdataok)\n",
    "    return\n",
    "\n",
    "def average2(inputs):      \n",
    "    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    layer_model = Model(inputs=inputs,outputs=x)\n",
    "    return layer_model\n",
    "\n",
    "average2 = average2(model_inputconv)\n",
    "\n",
    "def average3(inputs):      \n",
    "    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)    \n",
    "    layer_model = Model(inputs=inputs,outputs=x)\n",
    "    return layer_model\n",
    "\n",
    "average3 = average3(model_inputconv)\n",
    "\n",
    "def printGen22Resu(modelpr,num,runmode):\n",
    "    if runmode==0:\n",
    "        img = testdataok[0:60]   \n",
    "    else:\n",
    "        img = testdata[0:60]   \n",
    "    imgok =testdataok[0:60]\n",
    "    predict = modelpr.predict(img)    \n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    \n",
    "    \"\"\"\n",
    "    img = np.array(img)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    img = AveragePooling2D((2, 2))(img)\n",
    "    img = AveragePooling2D((2, 2))(img)\n",
    "    img = np.array(img)\n",
    "    \"\"\"\n",
    "    if num==40:        \n",
    "        img = average3.predict(img)\n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    if num==20:\n",
    "        img = average2.predict(img)    \n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    p5 = img[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [num,num,3]\n",
    "    p2.shape = [80,80,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [num,num,3]\n",
    "    p6.shape = [80,80,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [num,num,3]\n",
    "    p8.shape = [80,80,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(1, 3, 2)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def printGen23Resu(modelpr):\n",
    "    img = testdata[0:60]   \n",
    "    imgok =testdataok[0:60]\n",
    "    predict = modelpr.predict(img)    \n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    img = average3.predict(img)    \n",
    "    img = np.clip(img, 0., 1.)\n",
    "    \"\"\"\n",
    "    img = np.array(img)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    img = AveragePooling2D((2, 2))(img)\n",
    "    img = AveragePooling2D((2, 2))(img)\n",
    "    img = np.array(img)\n",
    "    \"\"\"\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    p5 = img[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [40,40,3]\n",
    "    p2.shape = [80,80,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [40,40,3]\n",
    "    p6.shape = [80,80,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [40,40,3]\n",
    "    p8.shape = [80,80,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(1, 3, 2)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def data_label(path):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    datalist = []\n",
    "    labellist = []\n",
    "    while True:\n",
    "        for line in f.readlines():\n",
    "            i+=1\n",
    "            j +=1\n",
    "            a = line.replace(\"\\n\",\"\")\n",
    "            b = a.split(\",\")\n",
    "            lable = b[1:]\n",
    "            imgname = path+b[0]\n",
    "            images = load_img(imgname)\n",
    "            images = img_to_array(images).astype('float32')\n",
    "            image = np.expand_dims(images,axis= 0)\n",
    "            lables = np.array(lable)\n",
    "            \n",
    "            lable= lables.reshape(1,10)\n",
    "            yield(image,lable)\n",
    "\n",
    "            \n",
    "def img_conv(path):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    datalist = []\n",
    "    labellist = []\n",
    "    \n",
    "    for line in f.readlines():        \n",
    "        \n",
    "        i+=1\n",
    "        j +=1\n",
    "        a = line.replace(\"\\n\",\"\")\n",
    "        b = a.split(\",\")\n",
    "        lable = b[1:]\n",
    "        imgname = path+b[0]\n",
    "            #images = load_img(imgname)\n",
    "            #images = img_to_array(images).astype('float32')\n",
    "            #image = np.expand_dims(images,axis= 0)\n",
    "        imgs = cv2.imread(imgname)\n",
    "        image2 = cv2.resize(imgs,(80,80))\n",
    "        cv2.imwrite(imgname,image2)\n",
    "        if (j%100==99):\n",
    "            print('now proc',j)\n",
    "\n",
    "def img_conv2(path,inum):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    datalist = []\n",
    "    labellist = []\n",
    "    \n",
    "    for line in f.readlines():        \n",
    "        \n",
    "        i+=1\n",
    "        j +=1\n",
    "        a = line.replace(\"\\n\",\"\")\n",
    "        b = a.split(\",\")\n",
    "        lable = b[1:]\n",
    "        imgname = path+b[0]\n",
    "            #images = load_img(imgname)\n",
    "            #images = img_to_array(images).astype('float32')\n",
    "            #image = np.expand_dims(images,axis= 0)\n",
    "        imgs = cv2.imread(imgname)\n",
    "        image2 = cv2.resize(imgs,(inum,inum))\n",
    "        cv2.imwrite(imgname,image2)\n",
    "        if (j%100==99):\n",
    "            print('now proc',j)\n",
    "\n",
    "def procData():\n",
    "    print('begin proc image')\n",
    "    img_conv(trainpath2)\n",
    "    print('train images complete')\n",
    "    img_conv(testpath2)\n",
    "    print('test images complete')\n",
    "\n",
    "\n",
    "def data_labelnoisy(path):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    dataresu = []\n",
    "    datalist = []\n",
    "    bPrintpic = False\n",
    "    for line in f.readlines():        \n",
    "        i+=1\n",
    "        j +=1\n",
    "        a = line.replace(\"\\n\",\"\")\n",
    "        b = a.split(\",\")\n",
    "        lable = b[1:]\n",
    "        imgname = path+b[0]\n",
    "        \n",
    "        #images = load_img(imgname)\n",
    "        #images = img_to_array(images).astype('float32')\n",
    "        #image = np.expand_dims(images,axis= 0)\n",
    "        \n",
    "        images = load_img(imgname)\n",
    "        images = img_to_array(images).astype('float32')\n",
    "        image = np.expand_dims(images,axis= 0)\n",
    "           \n",
    "        noise_factor = 2\n",
    "        #x_train_noisy = image + (noise_factor * np.random.normal(loc=0.0, scale=2.0, size=image.shape))\n",
    "\n",
    "        w = np.random.uniform(low = -50,high = 50,size =image.shape)\n",
    "        wmul = np.random.uniform(low = 0.7,high = 1.2,size =[1])\n",
    "        #print('wmul',wmul)\n",
    "        x_train_noisy = image + w*wmul\n",
    "        image = image/255\n",
    "        x_train_noisy = x_train_noisy/255\n",
    "        x_train_noisy = np.clip(x_train_noisy, 0., 1.)            \n",
    "        \n",
    "        image = image.astype('float32')\n",
    "        x_train_noisy = x_train_noisy.astype('float32')\n",
    "        #,dtype=float32\n",
    "        #image = tf.convert_to_tensor(image)\n",
    "        #x_train_noisy = tf.convert_to_tensor(x_train_noisy)\n",
    "        image.shape = [80,80,3]\n",
    "        x_train_noisy.shape = [80,80,3]\n",
    "        datalist.append(image)\n",
    "        dataresu.append(x_train_noisy)\n",
    "        \n",
    "        if (j%3000==2999):\n",
    "            print('now proc',j)\n",
    "            if (j>30000):                \n",
    "                return dataresu,datalist,j\n",
    "        if (j==1000):\n",
    "            bPrintpic = True\n",
    "            print('w',w)\n",
    "            print('source:')\n",
    "            print(image)\n",
    "            print('conv source:')\n",
    "            print(x_train_noisy)            \n",
    "            nl = np.random.uniform(low = 100,high = 500,size =[1])\n",
    "            nl = np.random.uniform(low = 500,high = 999,size =[1])\n",
    "            n1 = (int)(n1)-500\n",
    "            n2 = np.random.uniform(low = 500,high = 999,size =[1])\n",
    "            n2 = (int)(n2)\n",
    "            n1 = (int)(n2)-500\n",
    "            p1 = dataresu[n1]\n",
    "            p2 = dataresu[n2]\n",
    "            p5 = datalist[n1]\n",
    "            p6 = datalist[n2]\n",
    "            \n",
    "            \"\"\"\n",
    "            p1 = dataresu[1]\n",
    "            p2 = dataresu[2]\n",
    "            p5 = datalist[1]\n",
    "            p6 = datalist[2]\n",
    "            \"\"\"\n",
    "            \n",
    "            p1.shape = [80,80,3]\n",
    "            p2.shape = [80,80,3]\n",
    "            \n",
    "            p5.shape = [80,80,3]\n",
    "            p6.shape = [80,80,3]\n",
    "            p1 = p1.astype('float32')\n",
    "            p2 = p2.astype('float32')\n",
    "            \n",
    "            p5 = p5.astype('float32')\n",
    "            p6 = p6.astype('float32')\n",
    "            #p1 = p1/255\n",
    "            #p2 = p2/255\n",
    "            \n",
    "            #p5 = p5/255\n",
    "            #p6 = p6/255\n",
    "            #p1 = Reshape((120,120,3))(p1)\n",
    "            #p2 = Reshape((120,120,3))(p2)\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(p1)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(p2)\n",
    "            \n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(p5)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(p6)\n",
    "            #image.shape = [120, 120,3]\n",
    "            #plt.subplot(1, 2, 2)\n",
    "            #plt.imshow(image)\n",
    "            plt.show()\n",
    "            \n",
    "            \"\"\"\n",
    "            image = cv2.resize(x_train_noisy,(120,120))\n",
    "            image2 = cv2.resize(image,(120,120))\n",
    "            cv2.imshow('img',image)\n",
    "            cv2.imshow('img2',image2)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "           \n",
    "            \"\"\"\n",
    "    #ataresu = tf.convert_to_tensor(dataresu)\n",
    "    #datalist = tf.convert_to_tensor(datalist)\n",
    "    #traindata = np.array(traindata)\n",
    "    #traindataok= np.array(traindataok)\n",
    "    #testdata = np.array(testdata)\n",
    "    #testdataok = np.array(testdataok)\n",
    "    #dataresu = np.array(dataresu)\n",
    "    #datalist = np.array(datalist)\n",
    "    resui =(int)(i/2)\n",
    "    if (bPrintpic==False):\n",
    "        print(\"test image:\")\n",
    "        nl = np.random.uniform(low = resui+1,high = resui*2,size =[1])\n",
    "        n1 = (int)(n1)-resui\n",
    "        n2 = np.random.uniform(low = resui+1,high = resui*2,size =[1])\n",
    "        n2 = (int)(n2)\n",
    "        n1 = (int)(n2)-resui\n",
    "        p1 = dataresu[n1]\n",
    "        p2 = dataresu[n2]\n",
    "        p5 = datalist[n1]\n",
    "        p6 = datalist[n2]\n",
    "            \n",
    "            \n",
    "        p1.shape = [80,80,3]\n",
    "        p2.shape = [80,80,3]\n",
    "            \n",
    "        p5.shape = [80,80,3]\n",
    "        p6.shape = [80,80,3]\n",
    "        p1 = p1.astype('float32')\n",
    "        p2 = p2.astype('float32')\n",
    "            \n",
    "        p5 = p5.astype('float32')\n",
    "        p6 = p6.astype('float32')\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(p1)\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(p2)\n",
    "            \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.imshow(p5)\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.imshow(p6)\n",
    "        plt.show()\n",
    "            \n",
    "    return dataresu,datalist,j\n",
    "\n",
    "\n",
    "def data_chnagenoisy(datalist,icount):\n",
    "   \n",
    "    j = 0\n",
    "    i = -1\n",
    "    dataresu = []\n",
    "    \n",
    "    n1 =0\n",
    "    n2 =0\n",
    "    for i in range(icount):        \n",
    "        image = datalist[i]\n",
    "       \n",
    "        tm =np.random.uniform(low = 5,high = 12,size =[1])\n",
    "        tm= (int)(tm)\n",
    "        tm2 =np.random.uniform(low = -5,high = 5,size =[1])\n",
    "        tm2= (int)(tm)\n",
    "        if tm>9:\n",
    "            w = np.random.uniform(low = -50+tm2,high = 50+tm2,size =image.shape)\n",
    "        else:\n",
    "            if tm>7:\n",
    "                w = np.random.uniform(low = -60+tm2,high = 60+tm2,size =image.shape)\n",
    "            else:\n",
    "                w = np.random.uniform(low = -30+tm2,high = 70+tm2,size =image.shape)\n",
    "        \n",
    "        if tm>9:\n",
    "            w = w*1.2\n",
    "        else:\n",
    "            if tm>7:\n",
    "                w=w*0.9\n",
    "            else:\n",
    "                w=w*0.7\n",
    "        x_train_noisy = image*255 + w\n",
    "        x_train_noisy = x_train_noisy/255\n",
    "        x_train_noisy = np.clip(x_train_noisy, 0., 1.)            \n",
    "        \n",
    "        dataresu.append(x_train_noisy)\n",
    "        \n",
    "        if (j%1000==999):\n",
    "            print('now proc',j)            \n",
    "                \n",
    "        if (i==100):\n",
    "            #print('w',w)\n",
    "            #print('source:')\n",
    "            #print(image)\n",
    "            #print('conv source:')\n",
    "            #print(x_train_noisy)            \n",
    "            nl = np.random.uniform(low = 51,high = 100,size =[1])\n",
    "            \n",
    "            n2 = np.random.uniform(low = 51,high = 100,size =[1])\n",
    "            n2 = (int)(n2)\n",
    "            n1 = n2-50\n",
    "            p1 = dataresu[n1]\n",
    "            p2 = dataresu[n2]\n",
    "            p5 = datalist[n1]\n",
    "            p6 = datalist[n2]\n",
    "            p1.shape = [80,80,3]\n",
    "            p2.shape = [80,80,3]\n",
    "            \n",
    "            p5.shape = [80,80,3]\n",
    "            p6.shape = [80,80,3]\n",
    "            p1 = p1.astype('float32')\n",
    "            p2 = p2.astype('float32')\n",
    "            \n",
    "            p5 = p5.astype('float32')\n",
    "            p6 = p6.astype('float32')\n",
    "            #p1 = p1/255\n",
    "            #p2 = p2/255\n",
    "            \n",
    "            #p5 = p5/255\n",
    "            #p6 = p6/255\n",
    "            #p1 = Reshape((120,120,3))(p1)\n",
    "            #p2 = Reshape((120,120,3))(p2)\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(p1)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(p2)\n",
    "            \n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(p5)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(p6)\n",
    "            #image.shape = [120, 120,3]\n",
    "            #plt.subplot(1, 2, 2)\n",
    "            #plt.imshow(image)\n",
    "            plt.show()           \n",
    "    return dataresu\n",
    "\n",
    "\n",
    "def data_chnagenoisy2(datalist,icount,nproc):\n",
    "   \n",
    "    j = 0\n",
    "    i = -1\n",
    "    dataresu = []\n",
    "    \n",
    "    n1 =0\n",
    "    n2 =0\n",
    "    for i in range(icount):        \n",
    "        image = datalist[i]        \n",
    "        tm =np.random.uniform(low = 5,high = 12,size =[1])\n",
    "        tm= (int)(tm)\n",
    "        tm2 =np.random.uniform(low = -5,high = 5,size =[1])\n",
    "        tm2= (int)(tm)\n",
    "        tm5 =np.random.uniform(low = -2,high = 7,size =[1])\n",
    "        tm5= (int)(tm)\n",
    "        tm3 =np.random.uniform(low = -3,high = tm5+1,size =[1])\n",
    "        tm3= (int)(tm)\n",
    "        if tm>9:\n",
    "            w = np.random.uniform(low = -50+tm2+tm3,high = 50+tm2+tm3,size =image.shape)\n",
    "        else:\n",
    "            if tm>7:\n",
    "                w = np.random.uniform(low = -60+tm2+tm3,high = 60+tm2+tm3,size =image.shape)\n",
    "            else:\n",
    "                w = np.random.uniform(low = -30+tm2+tm3,high = 70+tm2+tm3,size =image.shape)\n",
    "        if tm>9:\n",
    "            w = w*1.2\n",
    "        else:\n",
    "            if tm>7:\n",
    "                w=w*0.9\n",
    "            else:\n",
    "                w=w*0.7\n",
    "        tm2 =np.random.uniform(low = 6,high = 66,size =[1])\n",
    "        tm2= (int)(tm2)\n",
    "        if tm2>12:\n",
    "            if nproc==0:\n",
    "                x_train_noisy = image*255 + w* ((tm2-12)/50+0.1)\n",
    "            if nproc==1:\n",
    "                x_train_noisy = image*255 + w* ((tm2-12)/80+0.1)\n",
    "            if nproc==2:\n",
    "                x_train_noisy = image*255 + w* ((tm2-12)/120+0.1)\n",
    "            x_train_noisy = x_train_noisy/255\n",
    "        else:\n",
    "            x_train_noisy = image\n",
    "        x_train_noisy = np.clip(x_train_noisy, 0., 1.)            \n",
    "        \n",
    "        dataresu.append(x_train_noisy)\n",
    "        \n",
    "        if (j%1000==999):\n",
    "            print('now proc',j)            \n",
    "                \n",
    "        if (i==100):\n",
    "            #print('w',w)\n",
    "            #print('source:')\n",
    "            #print(image)\n",
    "            #print('conv source:')\n",
    "            #print(x_train_noisy)            \n",
    "            nl = np.random.uniform(low = 51,high = 100,size =[1])\n",
    "            \n",
    "            n2 = np.random.uniform(low = 51,high = 100,size =[1])\n",
    "            n2 = (int)(n2)\n",
    "            n1 = n2-50\n",
    "            p1 = dataresu[n1]\n",
    "            p2 = dataresu[n2]\n",
    "            p5 = datalist[n1]\n",
    "            p6 = datalist[n2]\n",
    "            p1.shape = [80,80,3]\n",
    "            p2.shape = [80,80,3]\n",
    "            \n",
    "            p5.shape = [80,80,3]\n",
    "            p6.shape = [80,80,3]\n",
    "            p1 = p1.astype('float32')\n",
    "            p2 = p2.astype('float32')\n",
    "            \n",
    "            p5 = p5.astype('float32')\n",
    "            p6 = p6.astype('float32')\n",
    "            #p1 = p1/255\n",
    "            #p2 = p2/255\n",
    "            \n",
    "            #p5 = p5/255\n",
    "            #p6 = p6/255\n",
    "            #p1 = Reshape((120,120,3))(p1)\n",
    "            #p2 = Reshape((120,120,3))(p2)\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(p1)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(p2)\n",
    "            \n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(p5)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(p6)\n",
    "            #image.shape = [120, 120,3]\n",
    "            #plt.subplot(1, 2, 2)\n",
    "            #plt.imshow(image)\n",
    "            plt.show()           \n",
    "    return dataresu\n",
    "\n",
    "\n",
    "\n",
    "def printResu3(modeprev,modelpr,chang,num):\n",
    "    if  chang:\n",
    "        img = testdata[0:60]\n",
    "    else:\n",
    "        img = testdataok[0:60]\n",
    "    imgok =testdataok[0:60]\n",
    "    predictPrev = modeprev.predict(img)\n",
    "    predictPrev = np.clip(predictPrev, 0., 1.)\n",
    "    if chang:\n",
    "        predictPrev = data_chnagenoisy2(predictPrev,60,0)\n",
    "        predictPrev = np.clip(predictPrev, 0., 1.)\n",
    "        predictPrev = np.array(predictPrev)\n",
    "    \n",
    "    predict = modelpr.predict(predictPrev)\n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    if num==40:        \n",
    "        img = average3.predict(img)\n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    if num==20:\n",
    "        img = average2.predict(img)    \n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)   \n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p11 = predictPrev[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    \n",
    "    p5 = img[n2]\n",
    "    p51 = predictPrev[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p71 = predictPrev[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [num,num,3]\n",
    "    p11.shape = [80,80,3]\n",
    "    p2.shape = [80,80,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [num,num,3]\n",
    "    p51.shape = [80,80,3]\n",
    "    p6.shape = [80,80,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [num,num,3]\n",
    "    p71.shape = [80,80,3]\n",
    "    p8.shape = [80,80,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p11 = p11.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p51 = p51.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p71 = p71.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(p11)\n",
    "    plt.subplot(2, 2, 3)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(p51)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(p71)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def vgggen5_12_Next(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((20,20,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "           \n",
    "    x5= UpSampling2D()(x5)\n",
    "        \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "    #20*20\n",
    "  \n",
    "    x7= UpSampling2D()(x5)  #40*40 \n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7= UpSampling2D()(x7)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((20,20,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    \n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((10,10,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((10,10,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(400 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m]) \n",
    "        #activation=\"relu\",\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x3resu,x7,x10resu,x11])\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next'+str(num))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_inputconv5 = Input(shape=(20,20,128))\n",
    "\n",
    "\n",
    "\n",
    "model_inputconv3 = Input(shape=(20,20,3))\n",
    "\n",
    "vgggen5_12_Next1 =vgggen5_12_Next(model_inputconv3,0)\n",
    "vgggen5_12_Next2 =vgggen5_12_Next(model_inputconv3,1)\n",
    "vgggen5_12_Next3 =vgggen5_12_Next(model_inputconv3,2)\n",
    "\n",
    "def modevgg16_gen_19(inputs):      \n",
    "    \n",
    "    vgggen5_12_Next1.trainable = True    \n",
    "    vgggen5_12_Next2.trainable = True    \n",
    "    vgggen5_12_Next3.trainable = True    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x2 = vgggen5_12_Next1(x)\n",
    "    x3 = vgggen5_12_Next2(x)\n",
    "    x5 = vgggen5_12_Next3(x)\n",
    "    xrsu = concatenate([x2,x3,x5])\n",
    "    layer_model = Model(inputs=inputs,outputs=xrsu)\n",
    "    return layer_model\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "bload = True\n",
    "\n",
    "\n",
    "modevgg16_gen_19= modevgg16_gen_19(model_inputconv)\n",
    "\n",
    "modevgg16_gen_19.summary()\n",
    "\n",
    "def gencompile1():    \n",
    "    modevgg16_gen_19.compile(optimizer = 'adadelta', loss = 'binary_crossentropy',  metrics = ['acc'])\n",
    "\n",
    "def gencompile2():    \n",
    "    modevgg16_gen_19.compile(optimizer = optimizer, loss = msesum,  metrics = ['acc', lr_metric])\n",
    "    \n",
    "#20 -> 80 or 40 -> 80 or 80-80\n",
    "def trainvgg2(model,bloadmodel,num,printparr,chang,runmode):\n",
    "    global traindata,traindataok,traincount,trainprev\n",
    "    global testdata,testdataok,testcount\n",
    "    if bloadmodel:\n",
    "        gencompile2()\n",
    "    else:\n",
    "        gencompile1()\n",
    "    print('traindata shape:', traindata.shape)\n",
    "    \n",
    "    #model.compile(loss=msesum,optimizer=sgd)\n",
    "  \n",
    "    epoch_num = 3\n",
    "    #learning_rate = np.linspace(0.03,0.01,epoch_num)\n",
    "    #change_lr = LearningRateScheduler(lambda epoch:float(learning_rate[epoch]))\n",
    "    early_stop = EarlyStopping(monitor='val_loss',patience=20,verbose=1,mode='auto' )\n",
    "    check_point = ModelCheckpoint('face_CNN_model_finalvgg'+str(num)+'.h5',monitor='val_loss',verbose= 0,save_best_only= True,\n",
    "                                 save_weights_only=False,mode='auto',period=1)\n",
    "    callbacks_list= [check_point,early_stop]  \n",
    "    if bloadmodel:\n",
    "        model.load_weights('./face_CNN_model_finalvgg'+str(num))\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "   \n",
    "    \"\"\"\n",
    "    train_generator = datagen.flow_from_directory(  \n",
    "    './words',\n",
    "    target_size=(30, 30),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64)\n",
    "\n",
    "    model.fit_generator(train_generator, steps_per_epoch=500, epochs=50)\n",
    "    \"\"\"\n",
    "    \n",
    "    #,change_lr\n",
    "    #print('modevgg16_gen_18 train run:')\n",
    "    #model.load_weights('face_CNN_model_finalvgg18_2.h5')\n",
    "    \n",
    "    for i in range(1,3):\n",
    "        trainprev = traindataok\n",
    "        print('run times:',i)\n",
    "        if i>1:\n",
    "            model.load_weights('./face_CNN_model_finalvgg'+str(num))\n",
    "        #or (bloadmodel and i==1)\n",
    "        if (i%3==2 ):\n",
    "            datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images            \n",
    "            datagen.fit(trainprev)        \n",
    "            \n",
    "        if chang:        \n",
    "            traindata = data_chnagenoisy(trainprev,traincount)\n",
    "            traindata = np.array(traindata)\n",
    "            testdata = data_chnagenoisy(testdataok,testcount)\n",
    "            testdata = np.array(testdata)\n",
    "                       \n",
    "                \n",
    "        #print('begin proc image:')\n",
    "        if runmode==0:\n",
    "            model.fit(trainprev,trainprev,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epoch_num,\n",
    "              verbose=1,\n",
    "              validation_data=(testdataok,testdataok),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks_list)\n",
    "        else:\n",
    "            model.fit(traindata,trainprev,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epoch_num,\n",
    "              verbose=1,\n",
    "              validation_data=(testdata,testdataok),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks_list)\n",
    "        model.save_weights('./face_CNN_model_finalvgg'+str(num))\n",
    "        #model.fit_generator(traindata,traindataok,callbacks=[check_point,early_stop,change_lr],samples_per_epoch=int(train_samples// batch_size),\n",
    "        #                epochs =epoch_num,validation_steps =int(test_samples//batch_size),validation_data=(testdata,testdataok))\n",
    "        if runmode==0:\n",
    "            model.evaluate(testdataok[0:20],testdataok[0:20],steps=10)\n",
    "            model.evaluate(testdataok[30:50],testdataok[30:50],steps=10)       \n",
    "        else:\n",
    "            model.evaluate(testdata[0:20],testdataok[0:20],steps=10)\n",
    "            model.evaluate(testdata[30:50],testdataok[30:50],steps=10)  \n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testgen19(bload,running):\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if bload:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2)\n",
    "        testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "\n",
    "    trainvgg2(modevgg16_gen_19,running,31,20,False,0)  \n",
    "\n",
    "testgen19(True,False)\n",
    "#第二次运行改为 testgen19(True,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
